name: signal-service-qa
on:
  push:
  pull_request:

env:
  ENVIRONMENT: test
  CONFIG_SERVICE_URL: ${{ secrets.CONFIG_SERVICE_URL }}
  INTERNAL_API_KEY: ${{ secrets.INTERNAL_API_KEY }}
  SERVICE_NAME: signal_service
  ENABLE_HOT_RELOAD: "false"

jobs:
  lint-hygiene:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - name: Install ripgrep
        run: sudo apt-get update && sudo apt-get install -y ripgrep
      - name: Fail on forbidden URLs/secrets
        shell: bash
        run: |
          set -e
          echo "ðŸ” Checking for forbidden URLs and secrets..."
          
          # Check for external URLs (allow localhost and test domains)
          if rg "stocksblitz\.in|5\.223\.52\.98" app tests docs | rg -v localhost; then
            echo "âŒ External URLs detected in production code"; exit 1
          else 
            echo "âœ… No external URLs found"
          fi
          
          # Check for hardcoded API keys
          if rg "AShhRzWhfXd6IomyzZnE3d-lCcAvT1L5GDCCZRSXZGsJq7_eAJGxeMi-4AlfTeOc" .; then
            echo "âŒ Hardcoded API keys detected"; exit 1
          else
            echo "âœ… No hardcoded API keys found"
          fi
          
          # Check documentation for proper redaction
          if rg "API_KEY.*[A-Za-z0-9_-]{20,}" docs/ | rg -v "REDACTED|FROM_CONFIG_SERVICE"; then
            echo "âŒ Unredacted secrets in documentation"; exit 1
          else
            echo "âœ… Documentation properly redacted"
          fi
          
          # Check for hot reload enabled by default
          if rg 'ENABLE_HOT_RELOAD.*"true"' app/; then
            echo "âŒ Hot reload enabled by default"; exit 1
          else
            echo "âœ… Hot reload disabled by default"
          fi
          
          # Check for CORS wildcards
          if rg 'allow_origins.*\*' app/; then
            echo "âŒ CORS wildcard detected"; exit 1
          else
            echo "âœ… CORS configuration secure"
          fi

  smoke:
    runs-on: ubuntu-latest
    needs: lint-hygiene
    steps:
      - uses: actions/checkout@v4
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
      - name: Install dependencies
        run: |
          pip install --upgrade pip
          pip install -r requirements-dev.txt
      - name: Run smoke tests
        run: |
          echo "ðŸš€ Running smoke tests..."
          pytest tests/smoke/test_health_and_metrics.py tests/smoke/test_gateway_auth.py \
            -v --tb=short --junit-xml=smoke-results.xml
      - name: Upload smoke test results
        if: always()
        uses: actions/upload-artifact@v3
        with:
          name: smoke-test-results
          path: smoke-results.xml

  functional-golden:
    runs-on: ubuntu-latest
    needs: smoke
    steps:
      - uses: actions/checkout@v4
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
      - name: Install dependencies
        run: |
          pip install --upgrade pip
          pip install -r requirements-dev.txt
      - name: Run functional golden tests
        run: |
          echo "ðŸ“Š Running functional golden tests with real data..."
          pytest tests/functional/test_greeks_indicators_golden.py \
                 tests/functional/test_custom_signals_end_to_end.py \
            -v --tb=short --junit-xml=functional-results.xml
      - name: Upload functional test results
        if: always()
        uses: actions/upload-artifact@v3
        with:
          name: functional-test-results
          path: functional-results.xml

  integration:
    runs-on: ubuntu-latest
    needs: smoke
    steps:
      - uses: actions/checkout@v4
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
      - name: Install dependencies
        run: |
          pip install --upgrade pip
          pip install -r requirements-dev.txt
      - name: Run integration tests
        run: |
          echo "ðŸ”— Running integration tests with real services..."
          pytest tests/integration/test_ticker_service_integration.py \
                 tests/integration/test_instrument_service_integration.py \
                 tests/integration/test_marketplace_entitlement.py \
                 tests/integration/test_user_watchlist.py \
                 tests/integration/test_alert_comms_clients.py \
                 tests/integration/test_metrics_service_contract.py \
                 tests/integration/test_config_service_external.py \
            -v --tb=short --junit-xml=integration-results.xml
      - name: Generate contract matrix
        run: |
          echo "ðŸ“‹ Generating service contract matrix..."
          python scripts/generate_contract_matrix.py > docs/contract_matrix.md
      - name: Upload integration test results
        if: always()
        uses: actions/upload-artifact@v3
        with:
          name: integration-test-results
          path: integration-results.xml
      - name: Upload contract matrix
        if: always()
        uses: actions/upload-artifact@v3
        with:
          name: contract-matrix
          path: docs/contract_matrix.md

  security:
    runs-on: ubuntu-latest
    needs: [smoke, integration]
    steps:
      - uses: actions/checkout@v4
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
      - name: Install dependencies
        run: |
          pip install --upgrade pip
          pip install -r requirements-dev.txt
      - name: Run security tests
        run: |
          echo "ðŸ”’ Running security validation tests..."
          pytest tests/security/test_cors_and_auth.py \
                 tests/security/test_log_redaction.py \
                 tests/security/test_hot_reload_authz.py \
            -v --tb=short --junit-xml=security-results.xml
      - name: Upload security test results
        if: always()
        uses: actions/upload-artifact@v3
        with:
          name: security-test-results
          path: security-results.xml

  db:
    runs-on: ubuntu-latest
    needs: integration
    services:
      postgres:
        image: timescale/timescaledb:latest-pg14
        env:
          POSTGRES_DB: test_signal_service
          POSTGRES_USER: test_user
          POSTGRES_PASSWORD: test_password
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432
      redis:
        image: redis:7-alpine
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 6379:6379
    steps:
      - uses: actions/checkout@v4
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
      - name: Install dependencies
        run: |
          pip install --upgrade pip
          pip install -r requirements-dev.txt
      - name: Run database tests
        env:
          DATABASE_URL: postgresql://test_user:test_password@localhost:5432/test_signal_service
          REDIS_URL: redis://localhost:6379
        run: |
          echo "ðŸ—„ï¸ Running database integration tests..."
          pytest tests/integration/test_database_rw.py \
                 tests/integration/test_database_failure_modes.py \
            -v --tb=short --junit-xml=database-results.xml
      - name: Upload database test results
        if: always()
        uses: actions/upload-artifact@v3
        with:
          name: database-test-results
          path: database-results.xml

  hot-reload:
    runs-on: ubuntu-latest
    needs: integration
    env:
      ENABLE_HOT_RELOAD: "true"
    steps:
      - uses: actions/checkout@v4
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
      - name: Install dependencies
        run: |
          pip install --upgrade pip
          pip install -r requirements-dev.txt
      - name: Run hot reload tests
        run: |
          echo "ðŸ”„ Running hot reload end-to-end tests..."
          pytest tests/integration/test_hot_reload_end_to_end.py \
            -v --tb=short --junit-xml=hot-reload-results.xml
        env:
          ENABLE_HOT_RELOAD: "true"
      - name: Verify hot reload disabled post-test
        run: |
          echo "ðŸ”’ Verifying hot reload is disabled after test..."
          if [ "$ENABLE_HOT_RELOAD" = "true" ]; then
            echo "âš ï¸ Hot reload still enabled - this should be disabled in production"
          else
            echo "âœ… Hot reload properly disabled"
          fi
        env:
          ENABLE_HOT_RELOAD: "false"
      - name: Upload hot reload test results
        if: always()
        uses: actions/upload-artifact@v3
        with:
          name: hot-reload-test-results
          path: hot-reload-results.xml

  performance:
    runs-on: ubuntu-latest
    needs: [integration, db]
    steps:
      - uses: actions/checkout@v4
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
      - name: Install dependencies
        run: |
          pip install --upgrade pip
          pip install -r requirements-dev.txt
      - name: Run performance tests
        run: |
          echo "âš¡ Running performance and backpressure tests..."
          echo "SLO Targets:"
          echo "  - Core APIs: p95 â‰¤ 500ms, error rate â‰¤ 0.5%"
          echo "  - Metrics scrape: p95 â‰¤ 150ms, error rate â‰¤ 0.2%"
          echo "  - Health endpoints: p95 â‰¤ 100ms, error rate â‰¤ 0.1%"
          echo "  - Historical fetch: p95 â‰¤ 700ms, error rate â‰¤ 1%"
          
          pytest tests/performance/test_load_backpressure.py \
            -v --tb=short --junit-xml=performance-results.xml
      - name: Upload performance test results
        if: always()
        uses: actions/upload-artifact@v3
        with:
          name: performance-test-results
          path: performance-results.xml
      - name: Upload performance logs
        if: always()
        uses: actions/upload-artifact@v3
        with:
          name: performance-logs
          path: perf_logs/

  coverage:
    runs-on: ubuntu-latest
    needs: [functional-golden, integration, security, db]
    steps:
      - uses: actions/checkout@v4
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
      - name: Install dependencies
        run: |
          pip install --upgrade pip
          pip install -r requirements-dev.txt
          pip install coverage[toml] pytest-cov
      - name: Run coverage tests
        run: |
          echo "ðŸ“Š Running coverage analysis on critical modules..."
          echo "Target: â‰¥95% line/branch coverage on critical modules"
          
          pytest \
            tests/unit/test_pandas_ta_coverage_with_real_data.py \
            tests/unit/test_pyvollib_vectorized_engine_fallback.py \
            tests/unit/test_signal_delivery_service.py \
            tests/integration/test_distributed_coordination_coverage.py \
            tests/unit/test_cors_validation_coverage.py \
            --cov=app.core \
            --cov=app.services \
            --cov=app.clients \
            --cov-report=term-missing \
            --cov-report=html:coverage_html_report \
            --cov-report=xml:coverage.xml \
            --cov-fail-under=95 \
            --junit-xml=coverage-results.xml
      - name: Upload coverage test results
        if: always()
        uses: actions/upload-artifact@v3
        with:
          name: coverage-test-results
          path: coverage-results.xml
      - name: Upload coverage report
        if: always()
        uses: actions/upload-artifact@v3
        with:
          name: coverage-report
          path: |
            coverage_html_report/
            coverage.xml

  acceptance:
    runs-on: ubuntu-latest
    needs: [performance, coverage, hot-reload]
    steps:
      - uses: actions/checkout@v4
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
      - name: Download all artifacts
        uses: actions/download-artifact@v3
      - name: Generate Release Readiness Summary
        run: |
          echo "ðŸ“‹ Generating Release Readiness Summary..."
          python scripts/generate_release_readiness_summary.py .
      - name: Display Release Decision
        run: |
          echo "ðŸŽ¯ RELEASE READINESS ANALYSIS COMPLETE"
          echo "====================================="
          cat RELEASE_READINESS_SUMMARY.md
      - name: Upload Release Readiness Summary
        uses: actions/upload-artifact@v3
        with:
          name: release-readiness-summary
          path: RELEASE_READINESS_SUMMARY.md
      - name: Archive QA Artifacts with Release Summary
        run: |
          echo "ðŸ“¦ Creating comprehensive QA artifact bundle..."
          QA_BUNDLE="qa-validation-$(date +%Y%m%d_%H%M%S)"
          mkdir -p "$QA_BUNDLE"
          
          # Collect all test results and reports
          find . -name "*-results.xml" -exec cp {} "$QA_BUNDLE/" \; 2>/dev/null || true
          find . -name "contract_matrix.md" -exec cp {} "$QA_BUNDLE/" \; 2>/dev/null || true
          find . -name "coverage.xml" -exec cp {} "$QA_BUNDLE/" \; 2>/dev/null || true
          
          # Include release readiness summary
          cp RELEASE_READINESS_SUMMARY.md "$QA_BUNDLE/" 2>/dev/null || true
          
          # Create pipeline metadata
          cat > "$QA_BUNDLE/PIPELINE_METADATA.json" << EOF
          {
            "pipeline_run_id": "${{ github.run_id }}",
            "pipeline_run_number": "${{ github.run_number }}",
            "branch": "${{ github.ref_name }}",
            "commit_sha": "${{ github.sha }}",
            "commit_message": "${{ github.event.head_commit.message }}",
            "actor": "${{ github.actor }}",
            "timestamp": "$(date -u +%Y-%m-%dT%H:%M:%SZ)",
            "environment": "${{ env.ENVIRONMENT }}",
            "artifacts_included": [
              "test_results",
              "coverage_reports", 
              "contract_matrix",
              "performance_logs",
              "release_readiness_summary"
            ]
          }
          EOF
          
          echo "âœ… QA artifact bundle created: $QA_BUNDLE"
          ls -la "$QA_BUNDLE/"
      - name: Validate Release Criteria
        run: |
          echo "ðŸ” Validating release criteria..."
          
          # Check if release readiness summary indicates approval
          if grep -q "APPROVED FOR RELEASE" RELEASE_READINESS_SUMMARY.md; then
            echo "âœ… Release criteria met - approved for production"
            echo "release_approved=true" >> $GITHUB_OUTPUT
          elif grep -q "CONDITIONAL APPROVAL" RELEASE_READINESS_SUMMARY.md; then
            echo "âš ï¸ Conditional approval - review required"
            echo "release_approved=conditional" >> $GITHUB_OUTPUT
          else
            echo "âŒ Release criteria not met - deployment blocked"
            echo "release_approved=false" >> $GITHUB_OUTPUT
            exit 1
          fi